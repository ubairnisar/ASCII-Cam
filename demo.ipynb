{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubairnisar/ASCII-Cam/blob/master/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9M_fO5v8mW4"
      },
      "source": [
        "# PyTorch version\n",
        "\n",
        "import torch\n",
        "import torchvision  # Must import this for the model to load without error\n",
        "\n",
        "! mkdir -p models\n",
        "! wget -q -O models/nlf_l_multi.torchscript https://bit.ly/nlf_l_pt\n",
        "model = torch.jit.load('models/nlf_l_multi.torchscript').cuda().eval()\n",
        "image = torchvision.io.read_image('example_image.jpg').cuda()\n",
        "frame_batch = image.unsqueeze(0)\n",
        "\n",
        "with torch.inference_mode(), torch.device('cuda'):\n",
        "   pred = model.detect_smpl_batched(frame_batch)\n",
        "\n",
        "# SMPL Parametric predictions\n",
        "pred['pose'], pred['betas'], pred['trans']\n",
        "pred['joints3d'], pred['vertices3d']\n",
        "pred['joints2d'], pred['vertices2d']\n",
        "\n",
        "# Nonparametric joints and vertices\n",
        "pred['joints3d_nonparam'], pred['vertices3d_nonparam']\n",
        "pred['joints2d_nonparam'], pred['vertices2d_nonparam']\n",
        "pred['joint_uncertainties'], pred['vertex_uncertainties']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axm3SI936RD6"
      },
      "source": [
        "\n",
        "!# TF version\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as tfhub\n",
        "\n",
        "model = tfhub.load('https://bit.ly/nlf_l')  # Takes several minutes\n",
        "! wget -q https://images.pexels.com/photos/8928887/pexels-photo-8928887.jpeg?cs=srgb&dl=pexels-rdne-8928887.jpg&fm=jpg&w=640&h=960 -O example.jpg\n",
        "img = tf.image.decode_image(tf.io.read_file('example.jpg'))\n",
        "pred = model.detect_smpl(img)\n",
        "\n",
        "# SMPL Parametric predictions\n",
        "pred['pose'], pred['betas'], pred['trans']\n",
        "pred['joints3d'], pred['vertices3d']\n",
        "pred['joints2d'], pred['vertices2d']\n",
        "\n",
        "# Nonparametric joints and vertices\n",
        "pred['joints3d_nonparam'], pred['vertices3d_nonparam']\n",
        "pred['joints2d_nonparam'], pred['vertices2d_nonparam']\n",
        "pred['joint_uncertainties'], pred['vertex_uncertainties']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ToNwlWu2SxqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "image_person = PIL.Image.open('/content/77e5a831-d209-4ec3-84f7-e951003fc423.png')\n",
        "image_cloth = PIL.Image.open('/content/images.jpeg')\n",
        "\n",
        "client = genai.Client(api_key = \"AIzaSyDmUdYBkNgakoJHrg_5tmxATF6yabxZsEA\")\n",
        "\n",
        "text_input = ('Hi, This is a picture of me.'\n",
        "            'Can you tryon the cloth provided on my picture',)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp-image-generation\",\n",
        "    contents=[text_input, image_person , image_cloth],\n",
        "    config=types.GenerateContentConfig(\n",
        "      response_modalities=['Text', 'Image']\n",
        "    )\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "  if part.text is not None:\n",
        "    print(part.text)\n",
        "  elif part.inline_data is not None:\n",
        "    image = Image.open(BytesIO(part.inline_data.data))\n",
        "    image.save(\"output.png\")"
      ],
      "metadata": {
        "id": "PU1vzarBS8Ku"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8aHB1_STB_I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}